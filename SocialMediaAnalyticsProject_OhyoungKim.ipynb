{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa4623e8",
   "metadata": {},
   "source": [
    "Import libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00cb9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "## Facebook page analysis starter ##\n",
    "import html\n",
    "import string\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "## Additional package ##\n",
    "import seaborn as sns    # enhanced data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbe7f28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load Facebook dataset: Australian cosmetics company \"Australis Cosmetics\" page\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/multidis/hult-social-media-analytics/main/data/brand_posts.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e23ed5",
   "metadata": {},
   "source": [
    "Follow the analysis steps :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90182d8b",
   "metadata": {},
   "source": [
    "Step 1. Identify what types of posts in the dataset and how many entries of each post type are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2174ff43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Frequency for each type\n",
    "for tp in df[\"type\"].unique():\n",
    "    ntp = len(df[df[\"type\"] == tp])\n",
    "    print(f\"Type {tp} occurs {ntp} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8549774",
   "metadata": {},
   "source": [
    "Step 2. List the average number of shares for each post type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f99e3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average of each type of shares\n",
    "for etp in df[\"type\"].unique():\n",
    "    share = df[df[\"type\"] == etp][\"shares_count\"].mean()\n",
    "    print(f\"Type {etp} shared {share.round(decimals = 2)} times on average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abec0853",
   "metadata": {},
   "source": [
    "Step 3. Analyze the most common keywords occurring throughout the posts and visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bb15ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the text\n",
    "## Text cleaning function ##\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def text_cleanup(s):\n",
    "    # if not a string object, disregard\n",
    "    if not isinstance(s, str):\n",
    "        return ''\n",
    "    \n",
    "    s_unesc = html.unescape(re.sub(r\"http\\S+\", \"\", re.sub('\\n+', ' ', s)))\n",
    "    s_noemoji = s_unesc.encode('ascii', 'ignore').decode('ascii')\n",
    "    # normalize to lowercase and tokenize\n",
    "    wt = word_tokenize(s_noemoji.lower())\n",
    "    \n",
    "    # filter word-tokens\n",
    "    wt_filt = [w for w in wt if (w not in stop_words) and (w not in string.punctuation) and (w.isalnum())]\n",
    "    \n",
    "    # return clean string\n",
    "    return ' '.join(wt_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b196781f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add clean text column\n",
    "# NOTE: apply in pandas applies a function to each element of the selected column\n",
    "df['message_clean'] = df['message'].apply(text_cleanup)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665b7e85",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Combine all post text entries\n",
    "text_all = ' '.join(df['message_clean'])\n",
    "\n",
    "# Keywords occurring throughout all of the posts\n",
    "wc = WordCloud(width=1200, height=800, max_font_size=110, collocations=False).generate(text_all)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873abb5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Store the words used to create WordCloud as kwords\n",
    "kwords = WordCloud().process_text(text_all)\n",
    "\n",
    "# Transform that dictionary into a pandas DataFrame\n",
    "df_kwords = pd.DataFrame(list(kwords.items()), columns=['keyword', 'count']).set_index('keyword')\n",
    "\n",
    "# Plot a bar chart with the top keywords\n",
    "%matplotlib inline\n",
    "df_kwords.sort_values(by='count', ascending=False).head(20).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9501ad34",
   "metadata": {},
   "source": [
    "Step 4. Explore the times when posts were created for the most shared entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc33f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='shares_count', ascending=False).head(20)['created_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72de4503",
   "metadata": {},
   "source": [
    "Step 5. Identify the top-20 posts that received the most shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd8f9f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Top-shared entries: combined text\n",
    "text_shared = ' '.join(df.sort_values(by='shares_count', ascending=False)['message_clean'].head(20))\n",
    "\n",
    "# Proceed generating a word cloud\n",
    "wc = WordCloud(width=1200, height=800, max_font_size=110, collocations=False).generate(text_shared)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086d8b3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Store the words used to create WordCloud as kwords1\n",
    "kwords1 = WordCloud().process_text(text_shared)\n",
    "\n",
    "# Transform that dictionary into a pandas DataFrame\n",
    "df_kwords1 = pd.DataFrame(list(kwords1.items()), columns=['keyword', 'count']).set_index('keyword')\n",
    "\n",
    "# Plot a bar chart with the top keywords\n",
    "%matplotlib inline\n",
    "df_kwords1.sort_values(by='count', ascending=False).head(20).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d9b60d",
   "metadata": {},
   "source": [
    "Additional Step. Analyze the relationship between each count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebc4254",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Convert correlation matrix into a DataFrame\n",
    "df_corr = df.corr(method = 'pearson').round(decimals = 2)\n",
    "\n",
    "# specifying plot size (making it bigger)\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "\n",
    "\n",
    "# developing a spicy heatmap\n",
    "sns.heatmap(data       = df_corr, # the correlation matrix\n",
    "            cmap       = 'inferno',      # changing to SPICY colors\n",
    "            square     = True,          # tightening the layout\n",
    "            annot      = True,          # should there be numbers in the heatmap\n",
    "            linecolor  = 'black',       # lines between boxes\n",
    "            linewidths = 0.5)           # how thick should the lines be?\n",
    "\n",
    "\n",
    "# title and displaying the plot\n",
    "plt.title(\"\"\"\n",
    "Linear Correlation Heatmap for each count\n",
    "\"\"\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
